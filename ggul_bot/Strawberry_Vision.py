import cv2
import json
import numpy as np
from ultralytics import YOLO
import os
import time

# ì¹´ë©”ë¼ ì„¤ì •ê°’ - ìˆ˜ì •í•˜ì§€ ë§ê²ƒ
focal_length = 60    
baseline = 60  

cx = 448.0
cy = 336.0

def depth_calculate(y, x, disparity, Q):
    y = int(y)
    x = int(x)
    
    disparity_value = disparity[y, x]
    
    if disparity_value > 0:
            disparity_value = float(disparity_value)

            # ê¹Šì´ Z ê³„ì‚°
            Z = (focal_length * baseline) / disparity_value

            # ì¤‘ì‹¬ ì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
            X = ((x - cx) * Z) / focal_length
            Y = ((y - cy) * Z) / focal_length
            Y = -Y
            print(f"3D ì¢Œí‘œ (ì¹´ë©”ë¼ ê¸°ì¤€): ({X:.2f}, {Y:.2f}, {Z:.2f}) cm")
            return X,Y,Z 
    return None  

def detect_and_save(model_path="model/best3.pt", npz_path="stereo_calibration_result.npz", save_path="detected_objects.json",time_interval=10):
    
    image_save_dir = "saved_frames" 
    os.makedirs(image_save_dir, exist_ok=True)  

    # ìŠ¤í…Œë ˆì˜¤ ë¡œë“œ
    # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ ë° ì •ì˜
    data = np.load(npz_path)
    K1 = data['K1']
    dist1 = data['dist1']
    K2 = data['K2']
    dist2 = data['dist2']
    R = data['R']
    T = data['T']

    # resize = 0.7 ê¸°ì¤€
    new_dim = (896, 672)

    # ìŠ¤í…Œë ˆì˜¤ ì •í•© ë° ë¦¬ë§¤í•‘
    R1, R2, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(K1, dist1, K2, dist2, new_dim, R, T)

    # ë””ìŠ¤íŒ¨ë¦¬í‹° ë§µ ê³„ì‚°
    stereo = cv2.StereoSGBM_create(
        minDisparity=0,
        numDisparities=16 * 5,
        blockSize=5,
        P1=8 * 3 * 5**2,
        P2=32 * 3 * 5**2,
        disp12MaxDiff=1,
        uniquenessRatio=15,
        speckleWindowSize=45,
        speckleRange=4,
    )

    # YOLO ëª¨ë¸ ë¡œë“œ
    yolo_model = YOLO(model_path)

    # ì›¹ìº  ì—´ê¸°
    cap = cv2.VideoCapture(0)

    detected_objects = []
    last_save_time = time.time()

    while True:
        ret, frame = cap.read()
        if not ret:
            print("í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break

        height, width, _ = frame.shape
        img_left, img_right = frame[:, :width // 2], frame[:, width // 2:]

        img_left_resized = cv2.resize(img_left, new_dim)
        img_right_resized = cv2.resize(img_right, new_dim)

        # ì™œê³¡ ë³´ì •
        undistorted_left = cv2.undistort(img_left_resized, K1, dist1)
        undistorted_right = cv2.undistort(img_right_resized, K2, dist2)

        # ë³´ì •ëœ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray_left_undistorted = cv2.cvtColor(undistorted_left, cv2.COLOR_BGR2GRAY)
        gray_right_undistorted = cv2.cvtColor(undistorted_right, cv2.COLOR_BGR2GRAY)

        # ë¦¬ë§¤í•‘ ìƒì„±
        map1x, map1y = cv2.initUndistortRectifyMap(K1, dist1, R1, P1, new_dim, cv2.CV_32FC1)
        map2x, map2y = cv2.initUndistortRectifyMap(K2, dist2, R2, P2, new_dim, cv2.CV_32FC1)
        rectified_left = cv2.remap(gray_left_undistorted, map1x, map1y, cv2.INTER_LINEAR)
        rectified_right = cv2.remap(gray_right_undistorted, map2x, map2y, cv2.INTER_LINEAR)

        # ë””ìŠ¤íŒ¨ë¦¬í‹° ê³„ì‚°
        disparity = stereo.compute(rectified_left, rectified_right).astype(np.float32) / 16.0

        # ë””ìŠ¤íŒ¨ë¦¬í‹° ë§µ ì •ê·œí™”
        disparity_normalized = cv2.normalize(disparity, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)
        disparity_normalized = np.uint8(disparity_normalized)
        colormap = cv2.applyColorMap(disparity_normalized, cv2.COLORMAP_JET)

        # YOLO ì˜ˆì¸¡
        yolo_results_left = yolo_model.predict(img_left_resized, conf=0.5)
        yolo_img_left = yolo_results_left[0].plot()  # ì¢Œì¸¡ YOLO ê²€ì¶œ ê²°ê³¼ ì´ë¯¸ì§€

        # YOLO ê²°ê³¼ì—ì„œ ì‹ ë¢°ë„ ë° ê²½ê³„ ìƒì ì¶”ì¶œ
        boxes_left = yolo_results_left[0].boxes  # ì¢Œì¸¡ ì´ë¯¸ì§€ì—ì„œ ìƒì ì¶”ì¶œ
        scores_left = boxes_left.conf  # ì¢Œì¸¡ ì‹ ë¢°ë„
        class_indices_left = boxes_left.cls  # í´ë˜ìŠ¤ ì¸ë±ìŠ¤
        class_names = yolo_results_left[0].names  # í´ë˜ìŠ¤ ì´ë¦„ì´ í¬í•¨ëœ ë¦¬ìŠ¤íŠ¸

        detected_objects.clear()  # ìƒˆ í”„ë ˆì„ë§ˆë‹¤ ê°ì²´ ì •ë³´ ì´ˆê¸°í™”

        for i, (box_left, score_left) in enumerate(zip(boxes_left.xyxy, scores_left)):
            if score_left >= 0.5:  
                x1_left, y1_left, x2_left, y2_left = box_left.cpu().numpy()
                center_x = (x1_left + x2_left) / 2
                center_y = (y1_left + y2_left) / 2

                # ì¢Œì¸¡ ê¹Šì´ ê³„ì‚°
                depth_left = depth_calculate(center_y, center_x, disparity, Q)

                # Z ê°’ ì´ˆê¸°í™” (ê¸°ë³¸ ê°’ ì„¤ì •)
                X = center_x
                Y = center_y
                Z = 60.00 
                
                '''
                # ìŠ¤í…Œë ˆì˜¤ 3D
                if depth_left is not None:
                    X,Y,Z = depth_left 
                    label_left = f"Z: {Z:.2f} cm"
                else:
                    label_left = f"Z: {Z:.2f} cm" 

                class_name = class_names[int(class_indices_left[i])]  
                '''

                
                # 60cm ì „ë°© ëŒ€ìƒ
                if depth_left is not None:
                    X,Y,Z = depth_left
                    X = center_x
                    Y = center_y
                    label_left = f"Z: {Z:.2f} cm"
                else:
                    label_left = f"Z: {Z:.2f} cm" 

                class_name = class_names[int(class_indices_left[i])]  
                

                # ê°ì²´ ì •ë³´ ì¶”ê°€
                detected_objects.append({
                    "index": i,
                    # "class_name": class_name,  
                    "X": float(X),
                    "Y": float(Y),
                    "Z": float(Z)  
                })

                # ì¢Œì¸¡ YOLO ì´ë¯¸ì§€ì— ê¹Šì´ ë° 3D ì¢Œí‘œ ì¶”ê°€
                text_x_left, text_y_left = x1_left, y1_left - 25

                cv2.putText(
                    yolo_img_left,  # ì´ë¯¸ì§€
                    label_left,  # ì¶œë ¥í•  í…ìŠ¤íŠ¸
                    (int(text_x_left), int(text_y_left)),  # ìœ¤ê³½ì„  ìœ„ì¹˜ (ì•½ê°„ ì´ë™ì‹œì¼œì„œ ê·¸ë¦¼)
                    cv2.FONT_HERSHEY_SIMPLEX,  # ê¸€ê¼´
                    0.75,  # ê¸€ê¼´ í¬ê¸°
                    (0, 0, 255),  # ìƒ‰ìƒ (ë¹¨ê°„ìƒ‰)
                    2,  # ë‘ê»˜
                )


        cv2.imshow('Disparity + YOLO Detection', yolo_img_left)
        cv2.imshow('colormap',colormap)

        key = cv2.waitKey(1) & 0xFF  # í‚¤ ì…ë ¥ê°’ ë¯¸ë¦¬ ë°›ì•„ì˜¤ê¸°

        if key == ord('s') or time.time() - last_save_time >= time_interval:
            # ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ ì„¤ì •
            left_image_filename = f"left_image.jpg"
            right_image_filename = f"right_image.jpg"
            
            # íŒŒì¼ ê²½ë¡œ ì„¤ì •
            left_image_path = os.path.join(image_save_dir, left_image_filename)
            right_image_path = os.path.join(image_save_dir, right_image_filename)

            cv2.imwrite(left_image_path, img_left_resized)
            cv2.imwrite(right_image_path, img_right_resized)

            print(f"ì–‘ìª½ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ âœ…")

            # JSON íŒŒì¼ ì €ì¥ (ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ê°€)
            save_data = {
                "detected_objects": detected_objects,
                "image_path": [left_image_path,right_image_path]  # âœ… ì˜¬ë°”ë¥¸ ì´ë¯¸ì§€ ê²½ë¡œ ì €ì¥
            }
            with open(save_path, "w") as f:
                json.dump(save_data, f, indent=4)

            print(f"í˜„ì¬ í”„ë ˆì„ì˜ íƒì§€ëœ ê°ì²´ ì •ë³´ê°€ '{save_path}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            break

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

# ë§ˆìš°ìŠ¤ í´ë¦­ ì½œë°± (ì§€ì—­ ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ë¥¼ paramìœ¼ë¡œ ì „ë‹¬)
def mouse_callback(event, x, y, flags, param):
    image_save_dir = "saved_frames" 
    os.makedirs(image_save_dir, exist_ok=True)
    detected_objects = param["detected_objects"]
    if event == cv2.EVENT_LBUTTONDOWN:
        print(f"ğŸ“Œ ë§ˆìš°ìŠ¤ í´ë¦­ ìœ„ì¹˜: X={x}, Y={y}")
        Z = 60.0
        index = len(detected_objects)

        detected_objects.append({
            "index": index,
            "X": float(x),
            "Y": float(y),
            "Z": float(Z)
        })
        print(f"âœ… ê°ì²´ ì €ì¥: {detected_objects[-1]}")

        left_image_filename = f"left_image.jpg"
        right_image_filename = f"right_image.jpg"

        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        left_image_path = os.path.join(image_save_dir, left_image_filename)
        right_image_path = os.path.join(image_save_dir, right_image_filename)

        save_path="detected_objects.json"
        # ì €ì¥
        save_data = {
            "detected_objects": detected_objects,
            "image_path": [left_image_path, right_image_path]
        }
        with open(save_path, "w") as f:
            json.dump(save_data, f, indent=4)
        print(f"ğŸ’¾ JSON ì €ì¥ ì™„ë£Œ â†’ {save_path}")

def test_mode():
    cap = cv2.VideoCapture(0)
    new_dim = (896, 672)
    detected_objects = []  # ì§€ì—­ ë³€ìˆ˜ë¡œ ì„ ì–¸

    # paramìœ¼ë¡œ ë„˜ê¸¸ ë”•ì…”ë„ˆë¦¬ ìƒì„±
    callback_param = {"detected_objects": detected_objects}

    cv2.namedWindow('Test_image')
    cv2.setMouseCallback('Test_image', mouse_callback, callback_param)

    while True:
        ret, frame = cap.read()
        if not ret:
            print("âŒ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break

        height, width, _ = frame.shape
        img_left = frame[:, :width // 2]
        img_right = frame[:, width // 2:]

        img_left_resized = cv2.resize(img_left, new_dim)
        img_right_resized = cv2.resize(img_right, new_dim)

        cv2.imshow('Test_image', img_left_resized)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()